{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import data_augmentation as aug\n",
    "import robustdg_modified.dataset as dataset\n",
    "import robustdg_modified.config as cfg\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(f\"Num GPUs Available: {torch.cuda.device_count()}\")\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_device = torch.device(device)\n",
    "torch_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "\n",
    "data_loader_generator = torch.Generator()\n",
    "cfg.reproducibility.seed_everything(SEED, data_loader_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv = pd.read_csv(cfg.paths.LABELS_CSV[\"train\"])\n",
    "domain_csv = pd.read_csv(cfg.paths.DOMAIN_TRAIN_CSV[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = dataset.read.get_image_names(labels_csv)\n",
    "img_labels = dataset.read.get_one_hot_labels(labels_csv)\n",
    "img_domain = dataset.read.get_one_hot_domain(domain_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = dataset.utils.metadata.get_one_hot_encoded_names(img_labels)\n",
    "DOMAINS = dataset.utils.metadata.get_one_hot_encoded_names(img_domain)\n",
    "\n",
    "CLASSES, DOMAINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_CHANNELS, IMG_HEIGHT, IMG_WIDTH = dataset.utils.metadata.get_image_dimensions(cfg.paths.IMG_DIR[\"train\"])\n",
    "IMG_CHANNELS, IMG_HEIGHT, IMG_WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = dataset.utils.one_hot_encoding.convert_one_hot_df_to_names(img_labels, \"diagnosis\")\n",
    "diagnosis_method = dataset.utils.one_hot_encoding.convert_one_hot_df_to_names(img_domain, \"diagnosis_confirm_type\")\n",
    "img_information = pd.concat([img_names, diagnosis, diagnosis_method], axis=1)\n",
    "\n",
    "imgs_per_domain_label = aug.get_information_per_domain_label(\n",
    "    img_information, \n",
    "    column_names = [\"image\", \"diagnosis_confirm_type\", \"diagnosis\"]\n",
    ")\n",
    "imgs_per_label_domain = imgs_per_domain_label.swaplevel(i=\"diagnosis_confirm_type\", j=\"diagnosis\", axis=0).sort_index()\n",
    "imgs_per_label_domain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desired sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_per_label = imgs_per_domain_label.groupby(\"diagnosis\")[\"size\"].sum()\n",
    "total_per_label.quantile([0.40, 0.5, 0.60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based off of this we can use the interval: [400, 865]\n",
    "\n",
    "map_to_interval_fn = partial(aug.map_values_proportionally_to_interval, interval=(400, 865))\n",
    "\n",
    "modified_total_per_label = total_per_label.copy()\n",
    "modified_total_per_label[\"NV\"] = 2500 # too big (6705) initially\n",
    "\n",
    "desired_count_per_label = map_to_interval_fn(modified_total_per_label)\n",
    "desired_count_per_label.sort_values(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping sizes proportionally\n",
    "diagnosis_index = imgs_per_label_domain.index.get_level_values(\"diagnosis\")\n",
    "expanded_total_per_label = total_per_label[diagnosis_index]\n",
    "expanded_diagnosis_count = desired_count_per_label[diagnosis_index]\n",
    "\n",
    "normalized_count = imgs_per_label_domain[\"size\"] / expanded_total_per_label.to_numpy()\n",
    "desired_count_per_label_domain = (expanded_diagnosis_count.to_numpy() * normalized_count).astype(np.int32)\n",
    "desired_count_per_label_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_imgs_per_label_domain = pd.concat([imgs_per_label_domain, desired_count_per_label_domain.rename(\"desired size\")], axis=1)\n",
    "desired_imgs_per_label_domain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "# Pytorch Vision Preprocess Transforms\n",
    "# https://pytorch.org/hub/pytorch_vision_densenet/\n",
    "VISION_PREPROCESS = [\n",
    "    T.Resize(\n",
    "        (int(0.75 * IMG_HEIGHT), int(0.75 * IMG_WIDTH))\n",
    "    )\n",
    "]\n",
    "\n",
    "VISION_PREPROCESS_TENSOR = [\n",
    "    # T.ToTensor(),\n",
    "    # T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    # T.ToPILImage(),\n",
    "]\n",
    "\n",
    "preprocess_fn = T.Compose(VISION_PREPROCESS + VISION_PREPROCESS_TENSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are gonna store new names here\n",
    "data_augmented_information = desired_imgs_per_label_domain[[\"image\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_reduce = desired_imgs_per_label_domain[desired_imgs_per_label_domain[\"size\"] >= desired_imgs_per_label_domain[\"desired size\"]]\n",
    "to_augment = desired_imgs_per_label_domain[desired_imgs_per_label_domain[\"size\"] < desired_imgs_per_label_domain[\"desired size\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cfg.paths.IMG_DIR[\"augmented_train\"].mkdir(parents=True, exist_ok=False)\n",
    "except OSError:\n",
    "    raise Exception(\n",
    "        \"Directory already exists.\\n\"\n",
    "        \"If you want to use it to store only desired images,\"\n",
    "        \"you should delete the entire folder and then run this cell again.\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial function\n",
    "copy_imgs_fn = partial(\n",
    "    aug.augment_all_imgs,\n",
    "    from_dir = cfg.paths.IMG_DIR[\"train\"],\n",
    "    augmentation = preprocess_fn,\n",
    "    to_dir = cfg.paths.IMG_DIR[\"augmented_train\"],\n",
    "    img_extension = \"jpg\",\n",
    "    suffix = \"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (label, domain), (img_names, size, desired_size) in to_reduce.iterrows():\n",
    "\n",
    "    desired_img_names = np.random.choice(img_names, size=desired_size, replace=False)\n",
    "\n",
    "    data_augmented_information.loc[(label, domain), \"image\"] = desired_img_names\n",
    "    copy_imgs_fn(img_names=desired_img_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These augmentation shouldn't change the size of the image\n",
    "augmentation_fn = T.Compose(\n",
    "    VISION_PREPROCESS +\n",
    "    [\n",
    "        T.RandomPerspective(distortion_scale=0.2, p=0.50),\n",
    "        T.RandomHorizontalFlip(p=0.50),\n",
    "        T.RandomVerticalFlip(p=0.50),\n",
    "        T.RandomRotation((0, 360)),\n",
    "        T.RandomAdjustSharpness(sharpness_factor=2, p=0.50),\n",
    "    ] +\n",
    "    VISION_PREPROCESS_TENSOR\n",
    ")\n",
    "\n",
    "# Partial function\n",
    "augment_imgs_fn = partial(\n",
    "    aug.augment_all_imgs,\n",
    "    from_dir = cfg.paths.IMG_DIR[\"train\"],\n",
    "    augmentation = augmentation_fn,\n",
    "    to_dir = cfg.paths.IMG_DIR[\"augmented_train\"],\n",
    "    img_extension = \"jpg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (label, domain), (img_names, size, desired_size) in to_augment.iterrows():\n",
    "\n",
    "    new_img_names = []\n",
    "    \n",
    "    copy_imgs_fn(img_names=img_names)\n",
    "    new_img_names.extend(img_names)\n",
    "    \n",
    "    num_extra = desired_size % size\n",
    "    extra_imgs_names = np.random.choice(img_names, size=num_extra, replace=False)\n",
    "    augment_imgs_fn(img_names=extra_imgs_names, suffix=f\"_aug{0}\")\n",
    "    new_img_names.extend(map(lambda s: s + f\"_aug{0}\", extra_imgs_names))  \n",
    "\n",
    "    num_iterations = desired_size // size\n",
    "    for i in range(1, num_iterations):\n",
    "        augment_imgs_fn(img_names=img_names, suffix=f\"_aug{i}\")\n",
    "        new_img_names.extend(map(lambda s: s + f\"_aug{i}\", img_names))  \n",
    "    \n",
    "    data_augmented_information.loc[(label, domain), \"image\"] = np.array(new_img_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save .csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented_information[\"image\"].apply(len) == desired_imgs_per_label_domain[\"desired size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = data_augmented_information.explode(\"image\").sort_values(\"image\").reset_index()\n",
    "csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are one hot encoded\n",
    "# Indexing at CLASSES gets the correct order\n",
    "one_hot = pd.get_dummies(csvs.set_index(\"image\")[\"diagnosis\"])[CLASSES].reset_index()\n",
    "one_hot.to_csv(cfg.paths.LABELS_CSV[\"augmented_train\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain is just the name\n",
    "csvs[[\"image\", \"diagnosis_confirm_type\"]].to_csv(cfg.paths.DOMAIN_TRAIN_CSV[\"augmented_train\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('skin_cancer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "8faf78792ba83b5e5fb42215939bd717c7307b9d5737e597c662cebf863c6fa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
