{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import data_augmentation as aug\n",
    "import robustdg_modified.dataset as dataset\n",
    "import robustdg_modified.config as cfg\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(f\"Num GPUs Available: {torch.cuda.device_count()}\")\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_device = torch.device(device)\n",
    "torch_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "\n",
    "data_loader_generator = torch.Generator()\n",
    "cfg.reproducibility.seed_everything(SEED, data_loader_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv = pd.read_csv(cfg.paths.LABELS_CSV[\"train\"])\n",
    "domain_csv = pd.read_csv(cfg.paths.DOMAIN_TRAIN_CSV[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = dataset.read.get_image_names(labels_csv)\n",
    "img_labels = dataset.read.get_one_hot_labels(labels_csv)\n",
    "img_domain = dataset.read.get_one_hot_domain(domain_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = dataset.utils.metadata.get_one_hot_encoded_names(img_labels)\n",
    "DOMAINS = dataset.utils.metadata.get_one_hot_encoded_names(img_domain)\n",
    "\n",
    "CLASSES, DOMAINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_CHANNELS, IMG_HEIGHT, IMG_WIDTH = dataset.utils.metadata.get_image_dimensions(cfg.paths.IMG_DIR[\"train\"])\n",
    "IMG_CHANNELS, IMG_HEIGHT, IMG_WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = dataset.utils.one_hot_encoding.convert_one_hot_df_to_names(img_labels, \"diagnosis\")\n",
    "diagnosis_method = dataset.utils.one_hot_encoding.convert_one_hot_df_to_names(img_domain, \"diagnosis_confirm_type\")\n",
    "img_information = pd.concat([img_names, diagnosis, diagnosis_method], axis=1)\n",
    "\n",
    "imgs_per_domain_label = aug.get_information_per_domain_label(\n",
    "    img_information, \n",
    "    column_names = [\"image\", \"diagnosis_confirm_type\", \"diagnosis\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desired sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_per_domain_label[\"size\"].quantile([0.45, 0.5, 0.55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based off of this we can use the interval: [290, 430]\n",
    "map_to_interval_fn = partial(aug.map_values_proportionally_to_interval, interval=(290, 430))\n",
    "\n",
    "desired_count = (\n",
    "    imgs_per_domain_label[\"size\"]\n",
    "    .groupby(\"diagnosis_confirm_type\", group_keys=False)\n",
    "    .apply(map_to_interval_fn)\n",
    ")\n",
    "imgs_per_domain_label = pd.concat([imgs_per_domain_label, desired_count.rename(\"desired size\")], axis=1)\n",
    "imgs_per_domain_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are gonna store new names here\n",
    "data_augmented_information = imgs_per_domain_label[[\"image\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_reduce = imgs_per_domain_label[imgs_per_domain_label[\"size\"] >= imgs_per_domain_label[\"desired size\"]]\n",
    "to_augment = imgs_per_domain_label[imgs_per_domain_label[\"size\"] < imgs_per_domain_label[\"desired size\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cfg.paths.IMG_DIR[\"augmented_train\"].mkdir(parents=True, exist_ok=False)\n",
    "except OSError:\n",
    "    raise Exception(\n",
    "        \"Directory already exists.\\n\"\n",
    "        \"If you want to use it to store only desired images,\"\n",
    "        \"you should delete the entire folder and then run this cell again.\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial function\n",
    "copy_imgs_fn = partial(\n",
    "    aug.copy_all_imgs,\n",
    "    from_dir = cfg.paths.IMG_DIR[\"train\"],\n",
    "    to_dir = cfg.paths.IMG_DIR[\"augmented_train\"],\n",
    "    img_extension = \"jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (domain, label), (img_names, size, desired_size) in to_reduce.iterrows():\n",
    "\n",
    "    desired_img_names = np.random.choice(img_names, size=desired_size, replace=False)\n",
    "\n",
    "    data_augmented_information.loc[(domain, label), \"image\"] = desired_img_names\n",
    "    copy_imgs_fn(img_names=desired_img_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "augmentation_fn = T.Compose(\n",
    "    [\n",
    "        T.RandomApply([\n",
    "            T.CenterCrop(\n",
    "                [int(0.90 * IMG_HEIGHT), int(0.90 * IMG_WIDTH)]\n",
    "            )\n",
    "            ], p=0.25\n",
    "        ),\n",
    "        T.RandomHorizontalFlip(p=0.50),\n",
    "        T.RandomVerticalFlip(p=0.50),\n",
    "        T.RandomRotation((0, 360)),\n",
    "        T.RandomAdjustSharpness(sharpness_factor=2, p=0.50)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Partial function\n",
    "augment_imgs_fn = partial(\n",
    "    aug.augment_all_imgs,\n",
    "    from_dir = cfg.paths.IMG_DIR[\"train\"],\n",
    "    augmentation = augmentation_fn,\n",
    "    to_dir = cfg.paths.IMG_DIR[\"augmented_train\"],\n",
    "    img_extension = \"jpg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (domain, label), (img_names, size, desired_size) in to_augment.iterrows():\n",
    "\n",
    "    new_img_names = []\n",
    "    \n",
    "    copy_imgs_fn(img_names=img_names)\n",
    "    new_img_names.extend(img_names)\n",
    "    \n",
    "    num_extra = desired_size % size\n",
    "    extra_imgs_names = np.random.choice(img_names, size=num_extra, replace=False)\n",
    "    augment_imgs_fn(img_names=extra_imgs_names, suffix=f\"_aug{0}\")\n",
    "    new_img_names.extend(map(lambda s: s + f\"_aug{0}\", extra_imgs_names))  \n",
    "\n",
    "    num_iterations = desired_size // size\n",
    "    for i in range(1, num_iterations):\n",
    "        augment_imgs_fn(img_names=img_names, suffix=f\"_aug{i}\")\n",
    "        new_img_names.extend(map(lambda s: s + f\"_aug{i}\", img_names))  \n",
    "    \n",
    "    data_augmented_information.loc[(domain, label), \"image\"] = np.array(new_img_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save .csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented_information[\"image\"].apply(len) == imgs_per_domain_label[\"desired size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = data_augmented_information.explode(\"image\").sort_values(\"image\").reset_index()\n",
    "csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are one hot encoded\n",
    "# Indexing at CLASSES gets the correct order\n",
    "one_hot = pd.get_dummies(csvs.set_index(\"image\")[\"diagnosis\"])[CLASSES].reset_index()\n",
    "one_hot.to_csv(cfg.paths.LABELS_CSV[\"augmented_train\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain is just the name\n",
    "csvs[[\"image\", \"diagnosis_confirm_type\"]].to_csv(cfg.paths.DOMAIN_TRAIN_CSV[\"augmented_train\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('skin_cancer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "8faf78792ba83b5e5fb42215939bd717c7307b9d5737e597c662cebf863c6fa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
