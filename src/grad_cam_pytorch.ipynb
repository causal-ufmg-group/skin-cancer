{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440225c2-f2a5-4167-a3c8-21aa7e65b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import dataset\n",
    "import neural_network\n",
    "import config as cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae43e3",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7351ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = dataset.metadata.get_classes(cfg.paths.LABELS_CSV[\"train\"])  \n",
    "CLASSES, CLASSES.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78471900",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_CHANNELS, IMG_HEIGHT, IMG_WIDTH = dataset.metadata.get_image_dimensions(cfg.paths.IMG_DIR[\"train\"])\n",
    "IMG_CHANNELS, IMG_HEIGHT, IMG_WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae43e3",
   "metadata": {},
   "source": [
    "## Loading Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a451db",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "pl.seed_everything(SEED, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c56bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = dataset.SkinCancerDataModule(\n",
    "    cfg.paths.LABELS_CSV,\n",
    "    cfg.paths.IMG_DIR,\n",
    "    cfg.hparams.BATCH_SIZE,\n",
    "    cfg.hparams.DATALOADER_NUM_WORKERS,\n",
    "    transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed26b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neural_network.ConvNetwork(CLASSES.size, cfg.hparams.DROPOUT_RATE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 0\n",
    "CHECKPOINT_DIR = cfg.paths.LOG_DIR / f\"lightning_logs/version_{version}\" / \"checkpoints\"\n",
    "\n",
    "CHECKPOINT_PATHS = list(CHECKPOINT_DIR.glob(\"*.ckpt\")) \n",
    "CHECKPOINT_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce3dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_module: neural_network.NetworkModule = neural_network.NetworkModule.load_from_checkpoint(\n",
    "    CHECKPOINT_PATHS[0],\n",
    "    model=model,\n",
    "    channels=IMG_CHANNELS,\n",
    "    height=IMG_HEIGHT,\n",
    "    width=IMG_WIDTH,\n",
    "    num_classes=CLASSES.size,\n",
    "    learning_rate=cfg.hparams.LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae43e3",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup()\n",
    "data_module.batch_size = 1 # overwrite with one to get only one image\n",
    "\n",
    "dataloader = data_module.test_dataloader()\n",
    "imgs, labels = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab5589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "label = labels[0]\n",
    "img_tensor = imgs[0]\n",
    "\n",
    "img = to_pil_image(imgs[0].type(torch.uint8))\n",
    "\n",
    "CLASSES[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae43e3",
   "metadata": {},
   "source": [
    "## GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84afc641",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = [model_module.model.third_conv[-1]]\n",
    "\n",
    "cam = GradCAM(\n",
    "    model=model_module.model, \n",
    "    target_layers=target_layers, \n",
    "    use_cuda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f327aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [ClassifierOutputTarget(label)]\n",
    "\n",
    "# pass aug_smooth=True and eigen_smooth=True to apply smoothing.\n",
    "grayscale_cam = cam(input_tensor=imgs, targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_rgb_numpy = (img_tensor / 255).numpy()  # it needs to be a float between zero and one\n",
    "norm_rgb_numpy = np.moveaxis(norm_rgb_numpy, 0, -1)  # it needs to be of shape (height, width, channels)\n",
    "\n",
    "# grayscale_cam has only one image in the batch\n",
    "grayscale_cam_first = grayscale_cam[0, :]\n",
    "\n",
    "visualization = show_cam_on_image(norm_rgb_numpy, grayscale_cam_first, use_rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feca39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(visualization)\n",
    "plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('skin_cancer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "8faf78792ba83b5e5fb42215939bd717c7307b9d5737e597c662cebf863c6fa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
